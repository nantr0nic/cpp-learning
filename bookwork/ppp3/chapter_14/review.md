# Review Questions
1. Why would you want a graphical user interface?
2. When would you want a non-graphical user interface?
3. What is a software layer?
4. Why would you want to layer software?
5. What is a callback?
6. What is a widget?
7. Is Qt an acronym?
8. How do you pronounce Qt?
9. What other GUI tool kits have you heard of?
10. Which systems use the term widget and which prefer control?
11. What are examples of widgets?
12. When would you use an inbox?
13. What is the type of the value stored in an inbox?
14. When would you use a button?
15. When would you use a menu?
16. What is control inversion?
17. What is the basic strategy for debugging a GUI program?
18. Why is debugging a GUI program harder than debugging an "ordinary program using streams for I/O"?
19. How do you animate a widget?
---
# My Answers
1. This is a broad question but one encompassing answer is that there is a large domain of user that is accustomed to using software through graphical user interfaces. Where some technical users might be accustomed to using software through a command line interface, it seems most users are non-technical and thus expect the software they use to have a GUI. Also, there is obviously forms of software that are easier (or entirely dependent on) GUI such as photo/video editing, flow-charts, 3d modeling, multi-tracked audio recording, etc.
2. You would want a non-GUI for technical users where it is a reasonable assumption that the user is comfortable interacting with and perhaps benefitting from non-GUI applications. GUI makes many things 'easier' but non-GUI software can often achieve powerful functionality with greater functionality. Compare clicking through menus to select checkboxes versus a command-line where those flags can be quickly set with dashes. (And, then, for example on a Linux terminal, piped to other commands/programs/etc.)
3. The text didn't define what a software layer is but it described software layers in terms of an entire system so I will try to do the same. A GUI window is the end result of a complex system that is composed of everything from the device drivers that are responsible for drawing the pixels on a monitor, registering mouse movements, pointer coordinates and clicks; the operating system that allows those device drivers to constitute input/output of data from other devices connected to the system (such as memory, networking, the mouse and monitor, etc.); a graphics/GUI library that allows us to create code that results in GUI windows and buttons and interacts with the operating system to display the visual elements, create callbacks for the mouse being clicked somewhere in the window and so on; and, finally, our own program where we utilize the graphics/GUI library and our own code to create the functionality we desire in a program. Each of these is a "software layer" -- the top-most layer is probably our own program and it functions within the system by interacting with the layer beneath it, which interacts with the layer beneath that one and so on. Thus, an otherwise very complex set of interactions that is necessary for a system to produce something "as simple as" a GUI window is conceptually discernable as layers of software where each layer has its own input/output functions to the layers above and beneath it. In sum, I'd call a software layer a distinct set of functions that handles input and output to another set (i.e. layer) of functions -- assumedly, a layer depends on the functionality of the layer beneath it but provides (abstracts?) functionality to the layer above it for its own use.
4. Oh boy -- I might have accidentally answered this question in my previous answer. To keep it short and sweet: we want to layer software because: first, it simplifies the goals of a single layer (one piece of software can't "do it all") thus reducing the complexity of our task -- which, a fortiori, enables us to write more efficient and less error-prone code; second, we want a set of functions that are meant to solve a logically related set of problems to be distinct -- just how we separate classes in the way that seems to best represent the phenomena we are modeling, we want drivers that allow input/output from something like a mouse to be distinct from the code that draws text within a box on the monitor.
5. A callback is a "callback function" -- it is the function that the program calls for when a certain event takes place. In GUI programming the code logic is one of "control inversion" where the program is waiting for an event to occur and we have code that has a function that says "when event x occurs, call this (other) function" -- the function that is called is the callback function. We are using the Qt library for our GUI material -- we write a function and Qt provides the facilities required for that function to be called when a button is clicked. The function we wrote is the callback function (it is being "called back") that's called by the underlying Qt code.
6. A widget (which is a technical term) is anything that can be controlled or provides control -- in GUI programming this is any button, dropdown, menu, and so on. Generally, it is any element of a GUI that provides interaction with the user. Specifically, a widget is anything on the screen that is associated with an action (callback).
7. No. According to Wikipedia: "The toolkit was called Qt because the letter Q looked appealing in Haavard's Emacs typeface, and "t" was inspired by Xt, the X toolkit.[1]"
8. Like you would if you utter the two letters of its name: "Q" - "T". Or, in a more endearing fashion, like you'd call someone you find cute: "cutey" :)
9. I've heard of FLTK and GTK. As a Linux user, I've often had to choose between GTK and Qt apps.
10. I think GUI systems use the term 'widget' and perhaps non-GUI systems use 'control'?
11. As in answer 6: anything you can click in a GUI window to interact with the software such as buttons, menus, dialogue boxes with items you scroll through, drop down options, checkboxes, etc.
12. You would use an In_box when you want to accept text from the user through the GUI. An example is in the Lines_window class where the user entered the coordinates of points for the Open_polyline being drawn.
13. In the graphics library we are using it can be either a string or an int.
14. You would use a button when you want to a function to execute as the result of a mouse click. This could be anything from "close this window" to "open a menu", "add 5", or it could represent something like "yes I agree to these terms of service" or "yes this is what I want ordered, process my payment".
15. You would use a menu when you want to group together relevant functions/settings for a user to navigate easily.
16. In a command-line program code executes until some input or output is required for further execution -- in this instance, the program "gives away" its control until some input or output is fed to it that executes its next set of instructions. In GUI programming, this type of control is inverted in that the program keeps control (it is executing continuously) until some event occurs where it calls back the appropriate function for that event. Metaphorically, a command-line program "sleeps" until the next input is supplied and that triggers its next instructions, whereas a GUI program is constantly awake and monitoring events to call the appropriate function when whatever designated events occur.
17. To debug a GUI program: first, add code incrementally and test at each iteration before adding any new functionality or complexity -- then, refactor, test again. Second, you break the program down to its constituent parts (e.g. just the window, then add the buttons, then connect callbacks to those buttons and test each) and reconstitute it piece by piece. Bjarne suggests also checking all linker settings, comparing the code to already working programs, and explaining the code to a friend.
18. It is often the case that a GUI program can compile and "run" while you don't see anything at all -- this situation is one where there are no debugger messages for you to read and solve. An "ordinary" or command-line program can be marked with debug messages throughout to see "how far" you make it before a runtime error -- whereas GUI programs have at least two or more layers working together that can obscure the nature of the errors in the code.
19. You animate a widget with a timer! Animation is displaying pictures that change over time -- usually they change fast enough to produce the illusion of motion. While this 'illusion' probably is not the goal of animating widgets, the principle remains the same: changing an image (or, displaying varied images) over time -- this last element requires we use a timer.